{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "672cca6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Erwähnung                     Personenname  \\\n",
      "0                         DanielRem                       Daniel Rem   \n",
      "1                 Martin Horndacher                Martin Horndacher   \n",
      "2                Doktor JeorgMiller                      Jerg Miller   \n",
      "3                       HansWachter                     Hans Wachter   \n",
      "4         herzog Maximilianj gmahel  Elisabeth Renata von Lothringen   \n",
      "5                         schwester             Magdalena von Bayern   \n",
      "6            Dr. Wolfgang Hannemann               Wolfgang Hannemann   \n",
      "7                   rector collegij                  Melchior Hertel   \n",
      "8                            herzog       Ferdinand, Herzog (Bayern)   \n",
      "9                                er       Ferdinand, Herzog (Bayern)   \n",
      "10                             ihne       Ferdinand, Herzog (Bayern)   \n",
      "11  fraw Rosinageborner Hördtnittin              Rosina Würtenberger   \n",
      "\n",
      "   Geburtsjahr Todesjahr                                          Kategorie  \\\n",
      "0         1563      1626         Kaufleute, Gewerbetreibende, Dienstleister   \n",
      "1         1632      1632         Kaufleute, Gewerbetreibende, Dienstleister   \n",
      "2         1641      1642  Gelehrte und Schriftsteller; Angehörige von Kl...   \n",
      "3                                                               Bedienstete   \n",
      "4         1574      1635                        Angehörige der Aristokratie   \n",
      "5         1587      1628                        Angehörige der Aristokratie   \n",
      "6         1607      1607  Gelehrte und Schriftsteller; Angehörige von Kl...   \n",
      "7         1559      1634     Angehörige von Klerus und Ordensgemeinschaften   \n",
      "8         1550      1608                        Angehörige der Aristokratie   \n",
      "9         1550      1608                        Angehörige der Aristokratie   \n",
      "10        1550      1608                        Angehörige der Aristokratie   \n",
      "11        1606      1606                                           Sonstige   \n",
      "\n",
      "        Konfession  \n",
      "0   protestantisch  \n",
      "1   protestantisch  \n",
      "2       katholisch  \n",
      "3     keine Angabe  \n",
      "4       katholisch  \n",
      "5       katholisch  \n",
      "6       katholisch  \n",
      "7       katholisch  \n",
      "8       katholisch  \n",
      "9       katholisch  \n",
      "10      katholisch  \n",
      "11      katholisch  \n"
     ]
    }
   ],
   "source": [
    "# Personennamen: Normdatenverknüpfung & Metadatenanreicherung\n",
    "\n",
    "from lxml import etree as ET\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "### Schritt 1: Lade die LOD-Mapping-Datei und erstelle das Dictionary psn_to_person\n",
    "\n",
    "if not os.path.exists('hainhofer-lod.xml'):\n",
    "    print(\"Die Datei 'hainhofer-lod.xml' wurde nicht gefunden.\")\n",
    "    exit(1)\n",
    "\n",
    "lod_file = 'hainhofer-lod.xml'\n",
    "tree1 = ET.parse(lod_file)\n",
    "root1 = tree1.getroot()\n",
    "\n",
    "namespaces = {\n",
    "    'tei': 'http://www.tei-c.org/ns/1.0',\n",
    "    'schema': 'http://schema.org/',\n",
    "    'rdf': 'http://www.w3.org/1999/02/22-rdf-syntax-ns#',\n",
    "    'rdfs': 'http://www.w3.org/2000/01/rdf-schema#'\n",
    "}\n",
    "\n",
    "base_url = 'https://hainhofer.hab.de/register/personen/'\n",
    "\n",
    "psn_to_person = {}\n",
    "\n",
    "for person_name in root1.findall('.//rdf:Description', namespaces):\n",
    "    person = person_name.find('rdfs:label', namespaces)\n",
    "    psn = person_name.find('schema:mainEntityOfPage', namespaces)\n",
    "\n",
    "    if person is None or psn is None or not psn.text.startswith(base_url):\n",
    "        continue\n",
    "\n",
    "    url = psn.text[len(base_url):].strip()\n",
    "    person_text = person.text.strip()\n",
    "    psn_to_person[url] = person_text\n",
    "\n",
    "\n",
    "### Schritt 2: Lade die XML-Datei und extrahiere persons_list (person_text, psn_name)\n",
    "\n",
    "user_input = input('Geben Sie das Reiseziel und das Entstehungsjahr Ihres Berichts an (z.B. München 1603):')\n",
    "input_file = user_input.title() + '.xml'\n",
    "new_filename = input_file.lower().replace(\"ä\", \"ae\").replace(\"ö\", \"oe\").replace(\"ü\", \"ue\").replace(\"ü\", \"ue\").replace(\"ß\", \"ss\").replace(\" \", \"_\")\n",
    "\n",
    "if not os.path.exists(input_file):\n",
    "    print('Die gesuchte Datei wurde nicht gefunden.')\n",
    "    exit(1)\n",
    "\n",
    "tree2 = ET.parse(input_file)\n",
    "root2 = tree2.getroot()\n",
    "\n",
    "namespaces = {'tei': 'http://www.tei-c.org/ns/1.0'}\n",
    "\n",
    "def extract_text(elem):\n",
    "    return re.sub(r'\\s+', ' ', ''.join(elem.itertext())).strip()\n",
    "\n",
    "persons = root2.findall('.//tei:rs[@type=\"person\"][@role=\"present\"]', namespaces)\n",
    "\n",
    "persons_list = []\n",
    "\n",
    "for elem in persons:\n",
    "    parent = elem.getparent()\n",
    "    skip = False\n",
    "    while parent is not None:\n",
    "        if parent.tag == 'note' and parent.attrib.get('resp') == '#editor':\n",
    "            skip = True\n",
    "            break\n",
    "        if (parent.tag == 'p' or parent.tag == 'div') and parent.attrib.get('hand') == '#fremde_hand':\n",
    "            skip = True\n",
    "            break\n",
    "        parent = parent.getparent()\n",
    "\n",
    "    if skip:\n",
    "        continue\n",
    "\n",
    "    ref = elem.get('ref', None)\n",
    "    if not ref or not ref.startswith('psn:'):\n",
    "        continue\n",
    "\n",
    "    psn_name = ref[4:]\n",
    "    person_text = extract_text(elem)\n",
    "    persons_list.append((person_text, psn_name))\n",
    "\n",
    "\n",
    "### Schritt 3: Erstelle ein Dictionary: Zuordnung person_text → LOD-Personenname mittels psn_to_person\n",
    "\n",
    "normalization = {}\n",
    "\n",
    "for person_text, psn_name in persons_list:\n",
    "    person_name = psn_to_person.get(psn_name)\n",
    "    if person_name:\n",
    "        normalization[person_text] = person_name\n",
    "\n",
    "df_normalized = pd.DataFrame(normalization.items(), columns=['Erwähnung', 'Personenname'])\n",
    "\n",
    "\n",
    "### Schritt 4: Parsen des XHTML-Registers zur Erfassung von Personenmetadaten\n",
    "\n",
    "def extract_text(entry, xpath_expr):\n",
    "    result = entry.xpath(xpath_expr)\n",
    "    return result[0].strip() if result else ''\n",
    "\n",
    "def extract_list_text(entry, xpath_expr):\n",
    "    items = entry.xpath(xpath_expr)\n",
    "    texts = []\n",
    "    for item in items:\n",
    "        if isinstance(item, str):\n",
    "            text = item.strip()\n",
    "        else:\n",
    "            text = ''.join(item.itertext()).strip()\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        if text:\n",
    "            texts.append(text)\n",
    "    return '; '.join(texts)\n",
    "\n",
    "if not os.path.exists('register.xhtml'):\n",
    "    print(\"Die Datei 'register.xhtml' wurde nicht gefunden.\")\n",
    "    exit(1)\n",
    "\n",
    "with open('register.xhtml', 'rb') as f:\n",
    "    tree = ET.parse(f, ET.HTMLParser())\n",
    "\n",
    "entries = tree.xpath('//div[@id=\"psn\"]/div[contains(@class, \"entry\")]')\n",
    "\n",
    "birth_year_text = \"Angaben zum Geburtsjahr\"\n",
    "death_year_text = \"Angaben zum Todesjahr\"\n",
    "\n",
    "def extract_years(text):\n",
    "    if not text:\n",
    "        return (None, None)\n",
    "\n",
    "    text = re.sub(r'\\bca\\.?\\s*', '', text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Muster 1: zwischen X v. Chr. und Y n. Chr.\n",
    "    match = re.search(r'zwischen\\s+(\\d+)\\s+v\\.?\\s*Chr\\.?\\s+und\\s+(\\d+)', text, re.IGNORECASE)\n",
    "    if match:\n",
    "        year1 = -int(match.group(1))\n",
    "        year2 = int(match.group(2))\n",
    "        return min(year1, year2), max(year1, year2)\n",
    "\n",
    "    # Muster 2: zwischen X und Y (beide v. Chr.)\n",
    "    match = re.findall(r'(\\d+)\\s+v\\.?\\s*Chr\\.?', text, re.IGNORECASE)\n",
    "    if len(match) > 1:\n",
    "        years = sorted([-int(y) for y in match])\n",
    "        return years[0], years[-1]\n",
    "\n",
    "    # Muster 3: zwischen X und Y (beide n. Chr.)\n",
    "    match = re.search(r'zwischen\\s+(\\d+)\\s+und\\s+(\\d+)', text, re.IGNORECASE)\n",
    "    if match:\n",
    "        years = sorted([int(match.group(1)), int(match.group(2))])\n",
    "        return years[0], years[1]\n",
    "\n",
    "    # Muster 4: genaue Jahreszahl (v. Chr.)\n",
    "    match = re.search(r'(\\d+)\\s+v\\.?\\s*Chr\\.?', text, re.IGNORECASE)\n",
    "    if match:\n",
    "        year = -int(match.group(1))\n",
    "        return year, year\n",
    "\n",
    "    # Muster 5: genaue Jahreszahl (n. Chr.)\n",
    "    match = re.findall(r'(\\d{3,4})', text)\n",
    "    if match:\n",
    "        years = sorted([int(y) for y in match])\n",
    "        return years[0], years[-1]\n",
    "\n",
    "    return (None, None)\n",
    "\n",
    "persons = []\n",
    "\n",
    "for entry in entries:\n",
    "    name = extract_text(entry, './/h1[@class=\"prefname\"]/text()')\n",
    "\n",
    "    lifetime = extract_list_text(entry, './/div[@class=\"birthdeath\"]/p/text()')\n",
    "\n",
    "    birth_span = extract_years(lifetime)\n",
    "    death_span = extract_years(lifetime[lifetime.find(\"✝\"):]) if \"✝\" in lifetime else (None, None)\n",
    "\n",
    "    birth_year = birth_span[0]  # das frühere Jahr für Geburt\n",
    "    death_year = death_span[1]  # das spätere Jahr für Tod\n",
    "\n",
    "    if birth_year is not None and birth_year < 1500:\n",
    "        continue\n",
    "    if death_year is not None and death_year < 1600:\n",
    "        continue\n",
    "\n",
    "    category = extract_list_text(entry, './/div[@class=\"categorycontainer\"]//li')\n",
    "    excluded = ['Biblische Personen, Heilige', 'Mythologische Personen', 'Personifikationen']\n",
    "    if any(cat in category for cat in excluded):\n",
    "        continue\n",
    "\n",
    "    faith = extract_list_text(entry, './/div[@class=\"faithcontainer\"]//li/text()')\n",
    "\n",
    "    persons.append({\n",
    "        'Personenname': name,\n",
    "        'Geburtsjahr': str(birth_year) if birth_year is not None else '',\n",
    "        'Todesjahr': str(death_year) if death_year is not None else '',\n",
    "        'Kategorie': category,\n",
    "        'Konfession': faith\n",
    "    })\n",
    "\n",
    "df_register = pd.DataFrame(persons)\n",
    "\n",
    "def clean_cell(value):\n",
    "    if isinstance(value, list):\n",
    "        return '; '.join([v.strip() if isinstance(v, str) else str(v) for v in value])\n",
    "    elif isinstance(value, str):\n",
    "        return value.strip()\n",
    "    else:\n",
    "        return '' if pd.isna(value) else str(value).strip()\n",
    "\n",
    "for col in df_register.columns:\n",
    "    df_register[col] = df_register[col].apply(clean_cell)\n",
    "\n",
    "\n",
    "### Schritt 5: Zusammenführen der normalisierten Erwähnungen mit den Metadaten aus dem Register\n",
    "\n",
    "df_normalized['Personenname'] = df_normalized['Personenname'].str.strip()\n",
    "df_register['Personenname'] = df_register['Personenname'].str.strip()\n",
    "\n",
    "merged_df = pd.merge(df_normalized, df_register, on='Personenname', how='left').fillna('').astype(str)\n",
    "\n",
    "print(merged_df)\n",
    "\n",
    "\n",
    "### Schritt 6: Speichern des zusammengeführten DataFrames\n",
    "\n",
    "output_xlsx = new_filename.replace('.xml', '_personen_mit_metadaten.xlsx')\n",
    "output_csv = new_filename.replace('.xml', '_personen_mit_metadaten.csv')\n",
    "\n",
    "merged_df.to_excel(output_xlsx, index=False)\n",
    "merged_df.to_csv(output_csv, sep=';', index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
