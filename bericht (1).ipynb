{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bericht: Philipp Hainhofer\n",
    "Reiseberichte und Sammlungsbeschreibungen 1594-1636\n",
    "\n",
    "Unser Projekt basiert auf dem Quellenkorpus der digitalen Edition von Philipp Hainhofers Reise- und Sammlungsbeschreibungen (1594-1636), die systematisch erschlossen und für computergestützte Analyse zugänglich gemacht wurden. Das Projekt wird von der Deutschen Forschungsgemeinschaft gefördert und ist eine Kooperation zwischen der Herzog August Bibliothek und der Universität Trier.\n",
    "Im Zentrum stehen Hainhofers Reisen an europäische Höfe, seine diplomatischen Missionen und seine Rolle als Kunstvermittler. Die Texte bieten Einblicke in politische, kulturelle und materielle Austauschprozesse des 17. Jahrhunderts.\n",
    "Diese digitale Edition erschliesst diese Quelle erstmals systematisch und macht sie so für die computergestützte Analyse nutzbar.\n",
    "\n",
    "Philipp Hainhofer war eine zentrale Figur des kulturellen Austauschs im frühneuzeitlichen Europa. Als „cultural broker“ (Einführungstext der Edition und Datensammlung zur Kunst- und Kulturgeschichte der ersten Hälfte des 17. Jahrhunderts, hrsg. und eingeleitet von Michael Wenzel, Wolfenbüttel: Herzog August Bibliothek, 2020–2025)  bewegte er sich zwischen Politik, Diplomatie, Kunsthandel und höfischer Kultur. Seine Reiserelationen bilden den Kern seines schriftlichen Nachlasses und sind eine wertvolle Quelle für Kunstgeschichte, Geschichtswissenschaften und angrenzende Disziplinen.\n",
    "Ziel des Editionsprojekts ist die digitale Erschliessung dieser Reiseberichte - durch Faksimiles, Volltexte, kritische Apparate und Sachkommentare. Die Reiseberichte von 1603 bis 1636 sind bereits digital ediert und weitere folgen bis zum geplanten Projektabschluss im Jahr 2029. Neben der quellenkritischen Aufbereitung verfolgt das Projekt zwei wissenschaftliche Leitziele: die Untersuchung kultureller Vermittlung in einem konfliktreichen Europa und einen interdisziplinären Ansatz, der historische und kunsthistorische Perspektiven integriert. (Kommentierung zur Edition https://www.hab.de/kommentierte-digitale-edition-der-reise-und-sammlungsbeschreibungen-philipp-hainhofers-1578-1647/ letzter Zugriff 5.7.25)\n",
    "\n",
    "Wer war Philipp Hainhofer?\n",
    "Philipp Hainhofer (1578-1647) war eine bedeutende Vermittlerfigur im Europa des 17. Jahrhunderts. Er wurde in Augsburg geboren, studierte unter anderem in Italien und verfügte über umfangreiche Sprachkenntnisse, die ihm seine spätere, internationale Tätigkeit ermöglichten.\n",
    "Er war im Auftrag verschiedener Fürsten, Diplomaten und Städten tätig - unabhängig von deren Konfession - und pflegte ein weit verzweigtes Netzwerk in ganz Europa. Als sogenannter „cultural broker“ überschritt er politische, religiöse und kulturelle Grenzen und vermittelte nicht nur Kunstobjekte, Bücher und Möbel, sondern auch Informationen, Kontakte und Wissen.\n",
    "Die Hauptphase seiner Tätigkeit lag zwischen 1610 und 1620. Aus diesem Zeitraum stammen auch die meisten der Reiseberichte, die wir für unser Projekt ausgewertet haben.\n",
    "\n",
    "Der verwendete Quellenkorpus ist aus mehreren Gründen gut für unser Projekt geeignet:\n",
    "Die Texte liegen bereits strukturiert vor, sind digital durchsuchbar und für maschinelle Auswertungen aufbereitet.\n",
    "Inhaltlich bieten sie detaillierte Einblicke in die politischen, sozialen und kulturellen Netzwerke des 17. Jahrhunderts. Hainhofer dokumentiert seine Begegnungen, den Austausch von Objekten, die Beschreibung von Orten sowie den jeweiligen politischen Kontext.\n",
    "Zudem zeichnet sich der Korpus durch eine grosse zeitliche und räumliche Spannweite aus. Er umfasst über vier Jahrzehnte Reisetätigkeit und zahlreiche europäische Regionen. Diese Eigenschaften machen ihn besonders geeignet für digitale Methoden wie Netzwerkanalyse oder geobasierte Visualisierungen. Dies ist eine ideale Grundlage um mit digitalen Methoden Netzwerke, Bewegungen und Austauschprozesse sichtbar zu machen.\n",
    "\n",
    "Die zentrale Forschungsfrage unseres Projekts lautet: Wie verändern sich Hainhofers Netzwerke im Zeitverlauf, und welche Rolle spielen dabei Konfession und soziale Stellung der besuchten Personen?\n",
    "Ziel ist es, zu untersuchen, ob und wie sich Zusammensetzung seines Kontaktnetzwerks über die Jahre verschieben. Filter, welche uns geeignet erschienen waren: Zeiträume, geografische Regionen und konfessionelle Zugehörigkeit. \n",
    "\n",
    "Im ersten Schritt haben wir das Tool Voyant genutzt, um häufig vorkommende Begriffe im Korpus zu identifizieren und so erste inhaltliche Schwerpunkte und mögliche Ansatzpunkte für die vertiefende Analyse zu erkennen.\n",
    "\n",
    "Im weiteren Verlauf des Projekts haben wir uns dazu entschieden, mit den Personen- und Objekteregistern  der digitalen Edition zu arbeiten. Dabei zeigte sich, dass die tabellarische Erfassung am besten geeignet ist, um Personen, Orte und Objekte systematisch zu dokumentieren und eine Auswertung zu ermöglichen. Unser Vorgehen sieht daher vor, zunächst eine einzelne Reise vollständig zu erschliessen und darauf aufbauend das Projekt schrittweise zu erweitern.\n",
    "    \n",
    "Vorgehen\n",
    "Ausgangspunkt ist die Arbeit mit den vorhandenen Registern, aus denen wir relevante Entitäten (insbesondere Personen und Orte) im XML-Format extrahieren. Im nächsten Schritt erfolgt ein Entity Matching mit externen Referenzdaten aus dem Bereich der Linked Open Data (LOD), um die Einträge eindeutig zuzuordnen und anzureichern.\n",
    "Für die geobasierte Analyse werden die geografischen Koordinaten der erfassten Orte über den Dienst Geonames abgerufen. Darauf aufbauend erfolgt die Visualisierung der besuchten Orte sowie die Visualisierung der in den Texten beschriebenen Netzwerke.\n",
    "\n",
    "Weiterführende Forschung\n",
    "Potenzielle weiterführende Forschungsideen ergeben sich insbesondere aus der Skalierbarkeit von unserem Ansatz. Eine Möglichkeit besteht darin, die Analyse auf weitere Reisen Philipp Hainhofers auszuweiten. Die systematische Erfassung zusätzlicher Reiseberichte würde es erlauben, Veränderungen in Struktur und Zusammensetzung seines Netzwerks über längere Zeiträume hinweg zu analysieren: zum Beispiel im Zusammenhang mit politischen Umbrüchen wie dem Dreissigjährigen Krieg.\n",
    "\n",
    "Darüber hinaus bietet der Einsatz von Entity Matching mit Linked Open Data grosses Potenzial für die kontextuelle Anreicherung historischer Daten. Durch die Anbindung an etablierte Datenquellen könnten biografische, geografische und soziale Informationen ergänzt und vertieft werden.\n",
    "\n",
    "Eine weitere Ausbaumöglichkeit liegt in der Entwicklung dynamischer, zeitbasierter Visualisierungen. Interaktive Karten mit Zeitachsen könnten weitere Muster in Hainhofers Reisetätigkeit sichtbar machen: beispielsweise hinsichtlich Reisedauer, wiederholt besuchter Orte oder der Dichte und Stabilität seiner Netzwerke über die Zeit hinweg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# -------- Personennamen: Normdatenverknüpfung & Metadatenanreicherung --------\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import pandas as pd\n",
    "from lxml import etree as ET\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.styles import Font, PatternFill\n",
    "\n",
    "# Konstanten\n",
    "lod_file = 'hainhofer-lod.xml' # LOD-Mapping-Datei\n",
    "reg_file = 'register.xhtml' # Personenregister-Datei\n",
    "base_url = 'https://hainhofer.hab.de/register/personen/' # Basis-URL für PSN-IDs\n",
    "\n",
    "\n",
    "# Namespaces für die LOD-Datei\n",
    "namespaces_lod = {\n",
    "    'rdf': 'http://www.w3.org/1999/02/22-rdf-syntax-ns#',\n",
    "    'rdfs': 'http://www.w3.org/2000/01/rdf-schema#',\n",
    "    'schema': 'http://schema.org/',\n",
    "    'gndo': 'https://d-nb.info/standards/elementset/gnd#',\n",
    "    'ecrm': 'http://erlangen-crm.org/current/',\n",
    "    'psn': 'https://hainhofer.hab.de/register/personen/',\n",
    "    'wdt': 'http://www.wikidata.org/prop/direct/',\n",
    "}\n",
    "# Namespaces für die Berichte\n",
    "namespaces_report = {\n",
    "    'tei': 'http://www.tei-c.org/ns/1.0'\n",
    "}\n",
    "\n",
    "# Wikidata-Konfessionen\n",
    "wikidata_faith_map = {\n",
    "    'Q1841': 'katholisch',\n",
    "    'Q23540': 'protestantisch',\n",
    "    'Q106039': 'christlich allgemein'\n",
    "}\n",
    "\n",
    "# XPath-Ausdrücke zur Lokalisierung spezifischer Metadaten im Personenregister\n",
    "xpath_entries = '//div[@id=\"psn\"]/div[contains(@class, \"entry\")]' # Personeneintrag\n",
    "xpath_name = './/h1[@class=\"prefname\"]/text()' # Name\n",
    "xpath_lifedata = './/div[@class=\"birthdeath\"]/p/text()' # Lebensdaten (Geburts- und Todesjahr)\n",
    "xpath_category = './/div[@class=\"categorycontainer\"]//li' # Stand/Tätigkeit\n",
    "xpath_faith = './/div[@class=\"faithcontainer\"]//li/text()' # Konfession\n",
    "\n",
    "# Funktionen\n",
    "def parse_reg_metadata(reg_file):\n",
    "    \"\"\"\n",
    "    Parst die Register-XHTML-Datei und extrahiert Metadaten zu Personen.\n",
    "\n",
    "    Args:\n",
    "        reg_file_path (str): Pfad zur Datei 'register.xhtml'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame mit extrahierten Personen-Metadaten.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        tree_xhtml = ET.parse(reg_file, ET.HTMLParser())\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Die Datei '{reg_file}' wurde nicht gefunden. Bitte stellen Sie sicher, dass der Pfad korrekt ist.\")\n",
    "        sys.exit(1)\n",
    "    except ET.XMLSyntaxError as e:\n",
    "        print(f\"Fehler beim Parsen von '{reg_file}': {e}\")\n",
    "        sys.exit(1)\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler beim Laden von '{reg_file}': {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "def extract_text_from_elem(elem):\n",
    "    \"\"\"\n",
    "    Extrahiert den gesamten Text aus einem lxml-Element und normalisiert Leerschläge.\n",
    "    Entfernt mehrfache Leerschläge durch einfache und trimmt führende/abschliessende Leerzeichen.\n",
    "\n",
    "    Args:\n",
    "        elem (lxml.etree._Element): Das lxml-Element, aus dem der Text extrahiert werden soll.\n",
    "\n",
    "    Returns:\n",
    "        str: Der bereinigte und normalisierte Text des Elements.\n",
    "    \"\"\"\n",
    "    return re.sub(r'\\s+', ' ', ''.join(elem.itertext())).strip()\n",
    "\n",
    "def extract_xpath_text(entry, xpath_expr):\n",
    "    \"\"\"\n",
    "    Extrahiert den ersten passenden Text eines XPath-Ausdrucks aus einem lxml-Element und bereinigt ihn.\n",
    "\n",
    "    Args:\n",
    "        entry (lxml.etree._Element): Ein lxml-Element (z.B. ein Personeneintrag).\n",
    "        xpath_expr (str): Ein XPath-Ausdruck, der den gewünschten Text identifiziert.\n",
    "\n",
    "    Returns:\n",
    "        str: Der bereinigte Text oder ein leerer String, wenn kein Ergebnis gefunden wird.\n",
    "    \"\"\"\n",
    "    result = entry.xpath(xpath_expr)\n",
    "    return result[0].strip() if result else None\n",
    "\n",
    "def extract_list_text(entry, xpath_expr):\n",
    "    \"\"\"\n",
    "    Extrahiert Textinhalte aus einer Liste von XML-Elementen, bereinigt sie\n",
    "    und gibt sie als semikolon-getrennten String zurück. Nützlich für Listen\n",
    "    von Kategorien oder Konfessionen.\n",
    "\n",
    "    Args:\n",
    "        entry (lxml.etree._Element): Das lxml-Element.\n",
    "        xpath_expr (str): Der XPath-Ausdruck, der die Liste der Elemente identifiziert.\n",
    "\n",
    "    Returns:\n",
    "        str: Ein semikolon-getrennter String der extrahierten Texte.\n",
    "    \"\"\"\n",
    "    items = entry.xpath(xpath_expr)\n",
    "    list_texts = []\n",
    "    for item in items:\n",
    "        if isinstance(item, str): # Für XPath-Ausdrücke, die direkt Text zurückgeben\n",
    "            text = item.strip()\n",
    "        else: # Für XPath-Ausdrücke, die Elemente zurückgeben, deren Text extrahiert werden muss\n",
    "            text = ''.join(item.itertext()).strip()\n",
    "        text = re.sub(r'\\s+', ' ', text) # Normalisiert Leerzeichen innerhalb des Textes\n",
    "        if text:\n",
    "            list_texts.append(text)\n",
    "    return '; '.join(list_texts)\n",
    "\n",
    "def extract_lifedata(text):\n",
    "    \"\"\"\n",
    "    Extrahiert das Geburts- und Todesjahr aus einem Textstring.\n",
    "    Behandelt sowohl einzelne Jahre als auch Jahresspannen\n",
    "    (z.B. \"1573\", \"260 v. Chr.\", \"zwischen ca. 980 und 986\", \"zwischen 290 v. Chr. und 399 n. Chr.\").\n",
    "\n",
    "    Args:\n",
    "        text (str): Ein Textstring mit Lebensdaten.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Ein Tupel bestehend aus zwei Angaben: (Geburtsjahr, Todesjahr).\n",
    "               (None, None) wird ausgegeben, wenn kein passendes Muster gefunden wird.\n",
    "    \"\"\"\n",
    "    return None, None\n",
    "\n",
    "def extract_birth_date(lifedata):\n",
    "    \"\"\"\n",
    "    Extrahiert das Geburtsjahr oder den entsprechenden Zeitraum aus einem Lebensdaten-String.\n",
    "    Sucht nach dem Teil des Strings, der nach einem Sternzeichen ('*') beginnt und vor einem Kreuz ('✝') endet.\n",
    "\n",
    "    Args:\n",
    "        lifedata (str): Ein String mit den Lebensdaten der Person (z.B. \"*1573 ✝1620\").\n",
    "\n",
    "    Returns:\n",
    "        death_date_reg (str): Ein String mit dem Geburtsjahr oder dem entsprechenden Zeitraum.\n",
    "    \"\"\"\n",
    "\n",
    "    if \"*\" in lifedata:\n",
    "        text = lifedata[lifedata.find(\"*\")+1:] # Nimmt den Text nach dem Sternzeichen\n",
    "        text = text.split(\"✝\")[0] # Nimmt den Text vor dem Kreuz\n",
    "        return extract_lifedata(text)\n",
    "    return ''\n",
    "\n",
    "def extract_death_date(lifedata):\n",
    "    \"\"\"\n",
    "    Extrahiert das Todesjahr oder den entsprechenden Zeitraum aus einem Lebensdaten-String.\n",
    "    Sucht nach dem Teil des Strings, der nach einem Kreuz ('✝') beginnt.\n",
    "\n",
    "    Args:\n",
    "        lifedata (str): Ein String mit den Lebensdaten der Person (z.B. \"*1573 ✝1620\").\n",
    "\n",
    "    Returns:\n",
    "        death_date_reg (str): Ein String mit dem Todesjahr oder dem entsprechenden Zeitraum.\n",
    "    \"\"\"\n",
    "    if \"✝\" in lifedata:\n",
    "        text = lifedata[lifedata.find(\"✝\")+1:]\n",
    "        return extract_lifedata(text)\n",
    "    return ''\n",
    "\n",
    "def clean_cell(value):\n",
    "    \"\"\"\n",
    "    Bereinigt den Wert einer Zelle für die Ausgabe in Tabellen (z.B. Excel).\n",
    "    Konvertiert Listen von Werten in einen semikolon-getrennten String,\n",
    "    entfernt führende/abschliessende Leerzeichen von Strings und behandelt NaN-Werte.\n",
    "\n",
    "    Args:\n",
    "        value (any): Ein zu bereinigender Wert.\n",
    "\n",
    "    Returns:\n",
    "        str: Der bereinigte Wert als String.\n",
    "    \"\"\"    \n",
    "    if isinstance(value, list):\n",
    "        return '; '.join([v.strip() if isinstance(v, str) else str(v) for v in value])\n",
    "    elif isinstance(value, str):\n",
    "        return value.strip()\n",
    "    else:\n",
    "        return '' if pd.isna(value) else str(value).strip()\n",
    "    \n",
    "def prove_metadata(row):\n",
    "    \"\"\"\n",
    "    Entscheidet, welche Metadatenquelle verwendet werden soll:\n",
    "    \n",
    "    Regeln:\n",
    "    - Wenn beide Quellen identisch sind, werden Registerdaten verwendet.\n",
    "    - Wenn Registerdaten vorhanden sind, sich jedoch von der LOD-Version unterscheiden, werden LOD-Daten genommen.\n",
    "    - Wenn LOD-Daten fehlen, werden Register-Daten bevorzugt.\n",
    "    - Wenn beide Quellen leer sind, wird ein leerer String zurückgegeben.\n",
    "\n",
    "    Args:\n",
    "        row (pd.Series): Eine Zeile des DataFrames.\n",
    "\n",
    "    Returns:\n",
    "        Der ausgewählte Lebensdaten-String oder ein leerer String, wenn beide Quellen leer sind.\n",
    "    \"\"\"\n",
    "\n",
    "    lod = row['Lebensdaten_LOD']\n",
    "    reg = row['Lebensdaten_Register']\n",
    "\n",
    "    if lod and reg:\n",
    "        return reg if lod == reg else lod  # Bei Übereinstimmung: Register, sonst: LOD\n",
    "    if not lod:\n",
    "        return reg  # Nur Register vorhanden (auch wenn reg None ist): Register\n",
    "    return lod  # Nur LOD vorhanden: LOD\n",
    "\n",
    "def adjust_metadata(row):\n",
    "    \"\"\"\n",
    "    Gibt ein dict zurück mit den zu aktualisierenden Metadaten:\n",
    "    - Lebensdaten (LOD oder Register)\n",
    "    - Konfession (LOD, wenn LOD-Lebensdaten verwendet werden, sonst Register)\n",
    "    \"\"\"\n",
    "    if row['Lebensdaten_LOD'] and row['Lebensdaten_LOD'] != row['Lebensdaten_Register']:\n",
    "        # LOD-Lebensdaten unterscheiden sich und werden bevorzugt\n",
    "        return pd.Series({\n",
    "            'Lebensdaten': row['Lebensdaten_LOD'],\n",
    "            'Konfession': row.get('Konfession_LOD', None)\n",
    "        })\n",
    "    else:\n",
    "        # Kein Unterschied oder LOD leer -> Registerdaten verwenden\n",
    "        return pd.Series({\n",
    "            'Lebensdaten': row['Lebensdaten_Register'],\n",
    "            'Konfession': row.get('Konfession_Register')  if 'Konfession_Register' in row else None\n",
    "        })\n",
    "\n",
    "# --- Schritt 1: LOD-Mapping-Datei laden & PSN-IDs mit Personennamen verknüpfen ---\n",
    "# Dieser Schritt liest die LOD-Datei ein und erstellt ein Mapping-Dictionary (psn_to_name),\n",
    "# das PSN-IDs den standardisierten Personennamen zuordnet und Lebensdaten erfasst.\n",
    "\n",
    "try:\n",
    "    tree_lod = ET.parse(lod_file)\n",
    "    root_lod = tree_lod.getroot()\n",
    "except FileNotFoundError:\n",
    "    print(f\"Die Datei '{lod_file}' wurde nicht gefunden.\")\n",
    "    sys.exit(1)\n",
    "except ET.XMLSyntaxError as e:\n",
    "    print(f\"Fehler beim Parsen der Datei '{lod_file}':\\n{e}\")\n",
    "    sys.exit(1)\n",
    "except Exception as e:\n",
    "    print(f\"Fehler beim Laden der Datei '{lod_file}':\\n{e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Liste zur Speicherung von LOD-Personendaten\n",
    "lod_metadata = []\n",
    "\n",
    "# Dictionary für die PSN-IDs der Personen\n",
    "psn_name = {} # {PSN-ID: Personenname}\n",
    "\n",
    "# Dictionary für Lebensdaten (Geburts- und Todesjahr) der Personen\n",
    "psn_lifedata = {} # {PSN-ID: (Geburtsdatum, Todesdatum)}\n",
    "\n",
    "# Basis-URL für Einträge im Personenregister (Personen-URL = Basis-URL + PSN-ID)\n",
    "# Diese URL wird verwendet, um die PSN-ID aus der URL zu extrahieren\n",
    "base_url = 'https://hainhofer.hab.de/register/personen/'\n",
    "\n",
    "# Durchsucht die LOD-Datei nach Personeneinträgen\n",
    "for entry_lod in root_lod.findall('.//rdf:Description', namespaces_lod):\n",
    "    # Ungekürzte PSN-ID\n",
    "    person_url_lod = entry_lod.find('schema:mainEntityOfPage', namespaces_lod)\n",
    "    # Personenname\n",
    "    person_label_lod = entry_lod.find('rdfs:label', namespaces_lod)\n",
    "\n",
    "    # Überspringt Einträge, die keine gültige URL haben\n",
    "    # oder deren URL nicht mit der Basis-URL des Personenregisters beginnt\n",
    "    if person_label_lod is None or person_url_lod is None or not person_url_lod.text.startswith(base_url):\n",
    "        continue\n",
    "\n",
    "    # Extrahiert die PSN-ID aus der Personen-URL\n",
    "    psn_id = person_url_lod.text[len(base_url):].strip()\n",
    "    person_name = person_label_lod.text.strip()\n",
    "\n",
    "    # Speichert die Zuordnung {PSN-ID: Personenname} im Dictionary\n",
    "    psn_name[psn_id] = person_name\n",
    "\n",
    "    # Extrahiert die Geburts- und Todesdaten aus den gndo-Tags\n",
    "    birth_date = entry_lod.find('gndo:dateOfBirth', namespaces_lod)\n",
    "    death_date = entry_lod.find('gndo:dateOfDeath', namespaces_lod)\n",
    "    birth_date_lod = birth_date.text.strip() if birth_date is not None else None\n",
    "    death_date_lod = death_date.text.strip() if death_date is not None else None\n",
    "\n",
    "    # Tupel für Geburts- und Todesdatum: Ohne Konvertierung in numerische Werte, da die Lebensdaten in der LOD-Datei als Strings vorliegen.\n",
    "    lifedata_lod = (birth_date_lod, death_date_lod)\n",
    "\n",
    "    # Speichert die Zuordnung {PSN-ID: Lebensdaten_LOD} im Dictionary\n",
    "    # Dies ermöglicht die spätere Verknüpfung der Lebensdaten mit den Personennennungen im Bericht\n",
    "    psn_lifedata[psn_id] = lifedata_lod\n",
    "\n",
    "    # Extrahiert die Konfession einer Person\n",
    "    faith_lod_element = entry_lod.find('wdt:P140', namespaces_lod)\n",
    "    if faith_lod_element is not None:\n",
    "        wikidata_resource = faith_lod_element.attrib.get('w3:resource')\n",
    "    # Extrahiert die Wikipedia-Ressource, falls vorhanden\n",
    "    if wikidata_resource:\n",
    "        qid = wikidata_resource.split('/')[-1]\n",
    "    else:\n",
    "        qid = None\n",
    "    \n",
    "    # Konvertiert die Wikidata QID in eine lesbare Konfession\n",
    "    if faith_lod_element == 'Q1841':\n",
    "        faith_lod = 'katholisch'\n",
    "    elif faith_lod_element == 'Q23540':\n",
    "        faith_lod = 'protestantisch'\n",
    "    elif faith_lod_element == 'Q106039':\n",
    "        faith_lod = 'christlich allgemein'\n",
    "\n",
    "    # Fügt die Personendaten aus der LOD-Datei der Liste hinzu\n",
    "    lod_metadata.append({\n",
    "    'PSN-ID': psn_id,\n",
    "    'Name': person_name,\n",
    "    'Lebensdaten_LOD': lifedata_lod\n",
    "    'Konfession_LOD': faith_lod if faith_lod else None,\n",
    "    })\n",
    "\n",
    "# Erstellt ein DataFrame aus den LOD-Personendaten\n",
    "df_lod = pd.DataFrame(lod_metadata)\n",
    "\n",
    "print(f\"LOD-Mapping geladen. Es befinden sich {len(psn_name)} Personen im Mapping.\")\n",
    "# print(f\"LOD-Lebensdaten für {len(df_lod)} Personen erfasst.\")\n",
    "\n",
    "\n",
    "# --- Schritt 2: XML-Berichtsdatei laden & Personennungen extrahieren ---\n",
    "# Dieser Schritt fordert den Benutzer zur Eingabe eines Berichtsnamens auf (z.B. \"München 1603\"),\n",
    "# lädt die entsprechende XML-Datei und extrahiert alle im Bericht als presenten Personen.\n",
    "\n",
    "user_input = input('Geben Sie das Reiseziel und das Jahr des gesuchten Berichts an (z.B. München 1603): ')\n",
    "report_name = user_input + '.xml'\n",
    "\n",
    "try:\n",
    "    tree_report = ET.parse(report_name)\n",
    "    root_report = tree_report.getroot()\n",
    "except FileNotFoundError:\n",
    "    print(f\"Die Datei '{report_name}' wurde nicht gefunden.\")\n",
    "    sys.exit(1)\n",
    "except ET.XMLSyntaxError as e:\n",
    "    print(f\"Fehler beim Parsen der XML-Datei '{report_name}':\\n{e}\")\n",
    "    sys.exit(1)\n",
    "except Exception as e:\n",
    "    print(f\"Ein unerwarteter Fehler ist aufgetreten:\\n{e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Liste zur Speicherung aller Personennennungen und der damit entsprechenden PSN-IDs\n",
    "all_mentions_report = []\n",
    "\n",
    "# Sammelt Nennungen von Personen, die in der XML-Datei als 'present' markiert sind (d.h. unmittelbar in die Handlung involviert)\n",
    "persons = root_report.findall('.//tei:rs[@type=\"person\"][@role=\"present\"]', namespaces_report)\n",
    "\n",
    "for elem in persons:\n",
    "    parent = elem.getparent()\n",
    "    skip = False\n",
    "    # Prüft auf editorische Notizen oder Inhalte von 'fremder Hand'\n",
    "    while parent is not None:\n",
    "        # Schliesst editorische Notizen aus\n",
    "        if parent.tag == 'note' and parent.attrib.get('resp') == '#editor':\n",
    "            skip = True\n",
    "            break\n",
    "        # Schliesst Inhalte von 'fremder Hand' aus\n",
    "        if (parent.tag == 'p' or parent.tag == 'div') and parent.attrib.get('hand') == '#fremde_hand':\n",
    "            skip = True\n",
    "            break\n",
    "        # Geht zum nächsthöheren Elternelement\n",
    "        parent = parent.getparent()\n",
    "    if skip:\n",
    "        continue\n",
    "\n",
    "    ref = elem.get('ref', None)\n",
    "    # Stellt sicher, dass das 'ref'-Attribut existiert und mit 'psn:' beginnt\n",
    "    # Dies ist notwendig, um die PSN-ID korrekt zu extrahieren\n",
    "    if not ref or not ref.startswith('psn:'):\n",
    "        continue\n",
    "    # Extrahiert die PSN-ID aus dem 'ref'-Attribut\n",
    "    psn = ref[4:] # Entfernt das Präfix 'psn:'\n",
    "    # Extrahiert den reinen Text der Personennennung\n",
    "    person_mention = extract_text_from_elem(elem)\n",
    "\n",
    "    # Fügt die Verknüpfung {Personennennung: PSN-ID} zum Dictionary hinzu\n",
    "    all_mentions_report.append({\n",
    "    'Nennung': person_mention,\n",
    "    'PSN-ID': psn\n",
    "    })\n",
    "\n",
    "print(f\" Es wurden {len(all_mentions_report)} Personennennungen im Bericht '{report_name}' gefunden.\")\n",
    "\n",
    "\n",
    "# --- Schritt 3: Erstellung eines Dataframe mit den gemappten Personennamen ---\n",
    "# In diesem Schritt werden die extrahierten Personennennungen (aus Schritt 2)\n",
    "# mit den Personennamen aus dem psn_to_name Dictionary (aus Schritt 1) verknüpft.\n",
    "# Das Ergebnis ist ein DataFrame mit der spezifischen Nennung und dem zugehörigen Personennamen.\n",
    "# Die PSN-ID wird im Dataframe beibehalten, um die eindeutige Zuweisung der Lebensdaten zu ermöglichen.\n",
    "\n",
    "# Liste zur Speicherung von Dictionaries mit der Verknüpfung\n",
    "# {Nennung: Personenname} über die Verwendung der PSN-ID\n",
    "mapped_persons = []\n",
    "\n",
    "# Iteriert durch die Personennennungen\n",
    "for person_mention, psn in all_mentions_report:\n",
    "    # Holt den Personennamen aus dem zuvor geladenen psn_to_name Dictionary\n",
    "    person_name = psn_name.get(psn)\n",
    "    if person_name:\n",
    "        # Fügt die Nennung und den Personennamen zur Liste hinzu\n",
    "        mapped_persons.append({\n",
    "            'Nennung': person_mention,\n",
    "            'PSN-ID': psn,\n",
    "            'Name': person_name\n",
    "        })\n",
    "\n",
    "# Erstellen des DataFrames für die Personennennungen im Bericht\n",
    "df_report_mentions = pd.DataFrame(all_mentions_report)\n",
    "\n",
    "# Führt die gemappten Personennennungen mit den PSN-IDs zusammen und fügt die PSN-ID hinzu\n",
    "df_report_persons = pd.merge(\n",
    "    df_report_mentions,\n",
    "    df_lod,\n",
    "    left_on='psn',\n",
    "    right_on='PSN_ID',\n",
    "    how='left'\n",
    ").drop(columns=['PSN_ID'])\n",
    "\n",
    "# Erstellt einen Pandas DataFrame aus den gemappten Personen\n",
    "df_mapping = pd.DataFrame(mapped_persons)\n",
    "\n",
    "\n",
    "# --- Schritt 4: XHTML-Register parsen & Metadaten erfassen ---\n",
    "# Dieser Schritt liest das Personenregister ein, um Metadaten zu Personen zu extrahieren,\n",
    "# wie Geburts- und Todesjahr, Kategorie (Stand/Tätigkeit) und Konfession.\n",
    "# Dabei werden bestimmte Personengruppen (z.B. biblische Figuren) ausgeschlossen,\n",
    "# denn auch sie können als 'present' markiert sein.\n",
    "\n",
    "reg_file = 'register.xhtml'\n",
    "\n",
    "try:\n",
    "    tree_xhtml = ET.parse(reg_file)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Die Datei '{report_name}' wurde nicht gefunden.\")\n",
    "    sys.exit(1)\n",
    "except ET.XMLSyntaxError as e:\n",
    "    print(f\"Fehler beim Parsen der XML-Datei '{report_name}':\\n{e}\")\n",
    "    sys.exit(1)\n",
    "except Exception as e:\n",
    "    print(f\"Ein unerwarteter Fehler ist aufgetreten:\\n{e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "\n",
    "# Liste zur Speicherung der angereicherten Personeninformationen aus dem Register\n",
    "persons_reg = []\n",
    "\n",
    "# Findet alle Personen-Einträge im Register basierend auf dem definierten XPath\n",
    "entries_reg = tree_xhtml.xpath(xpath_entries)\n",
    "\n",
    "# Tupel für Geburts- und Todesjahr aus dem Register\n",
    "lifedata_reg = (extract_birth_date, extract_death_date)\n",
    "    \n",
    "# Ausschlusskategorien\n",
    "excluded_category_keywords = ['Biblische Personen, Heilige', 'Mythologische Personen', 'Personifikationen'] # Ausschluss irrelevanter Kategorien im Register\n",
    "excluded_name_keywords = ['biblisch', 'mythologisch', 'Theaterfigur', 'Personifikation', 'Apostel', 'Prophet', 'Jesus Christus'] # Ausschluss von Personentypen ohne konsistente Kategorieangaben\n",
    "\n",
    "# Hauptschleife zur Zuweisung von Metadaten aus dem Register\n",
    "for entry in entries_reg:\n",
    "    # Name\n",
    "    name = extract_xpath_text(entry, xpath_name)\n",
    "    # Lebensdaten\n",
    "    lifedata_reg = extract_xpath_text(entry, xpath_lifedata)\n",
    "    # Personen ohne Lebensdaten werden nicht ausgeschlossen, da es sich oft um Personen niedrigeren sozialen Ranges handelt, die einen tiefen Quellenabdruck aufweisen. Für den Auschluss irrelevanter Einträge wie mythologischer Personen müssen Ausschlusskriterien herangezogen werden.\n",
    "    # Schliesst Figuren und historische Persöhnlichkeiten aus, auch wenn diese unter dem Tag 'present' aufgeführt sind\n",
    "    if any(cat in category for cat in excluded_category_keywords):\n",
    "        continue\n",
    "    # Schliesst Figuren und historische Persönlichkeiten aus, auch wenn sie nicht mit einer entsprechenden Kategorie im Register versehen sind\n",
    "    if any(x in name.lower() for x in excluded_name_keywords):\n",
    "        continue\n",
    "    # Kategorie (Stand/Tätigkeit)\n",
    "    category = extract_list_text(entry, xpath_category)\n",
    "    # Konfession\n",
    "    faith_reg = extract_list_text(entry, xpath_faith)\n",
    "    # Folgt der Praxis des Registers: Wenn keine Konfession angegeben ist, wird 'keine Angabe' verwendet\n",
    "    # Dies ist wichtig, um die Konsistenz mit der Edition zu wahren\n",
    "    if faith_reg is None:\n",
    "        faith_reg = 'keine Angabe'\n",
    "    # Mehrere Konfessionen werden durch ein Semikolon getrennt und weisen auf eine Konversion hin\n",
    "    # (so bedeutet z.B. '(katholisch; protestantisch)', dass die Person zuerst katholischen Glaubens war und dann zum Protestantismus konvertierte)\n",
    "\n",
    "    # Fügt die Personendaten der Liste hinzu\n",
    "    persons_reg.append({\n",
    "        'Name': name,\n",
    "        'Lebensdaten_Register': lifedata_reg,\n",
    "        'Konfession_Register': faith_reg,\n",
    "        'Kategorie': category\n",
    "    })\n",
    "\n",
    "# Erstellt einen DataFrame aus den gesammelten Register-Metadaten\n",
    "df_reg = pd.DataFrame(persons_reg)\n",
    "\n",
    "# Wendet die Bereinigungsfunktion auf alle Spalten des Metadaten-DataFrames an\n",
    "for col in df_reg.columns:\n",
    "    df_reg[col] = df_reg[col].apply(clean_cell)\n",
    "\n",
    "# Gibt die Anzahl der erfassten Personen im Register aus\n",
    "print(f\"Register-Metadaten geladen. Es wurden {len(persons_reg)} Personen im Register erfasst.\")\n",
    "\n",
    "\n",
    "# --- Schritt 5: Prüfung auf Mehrdeutigkeiten ---\n",
    "# Da die Metadaten über den Personennamen zugeordnet werden, kann es bei Namensvetter*innen zu falschen Datenzuweisungen kommen.\n",
    "# Dies kommt im Personenregister tatsächlich vor (z.B. Magdalena von Bayern: (1388-1410) und (1587-1628)).\n",
    "# Im Register-Dataframe werden in solchen Fällen die Metadaten der ersten Person erfasst.\n",
    "# Da Metadaten aus dem Personenregister nicht mit den eindeutigen PSN-IDs verknüpft sind, muss die LOD-Datei bemüht werden.\n",
    "# In der Linked Open Data sind einzelne die Personen und Orte betreffende Angaben enthalten.\n",
    "# Ihre Bedeutungen können auf https://eos.hypotheses.org/293 nachgelesen werden.\n",
    "# Bei Personen sind vor allem Lebensdaten von Bedeutung. Sind diese vorhanden, können sie als Unterscheidungsmerkmale dienen.\n",
    "# Struktur df_reg: PSN_ID (eindeutig) -> Name (evtl. mehrdeutig) -> Lebensdaten_reg (fehleranfällig)\n",
    "# Struktur df_lod:      PSN_ID (eindeutig) -> Lebensdaten_LOD (seltener vorhanden, jedoch korrekt zugewiesen)\n",
    "\n",
    "df_lod_data = df_mapping.merge(df_lod, on='PSN_ID', how='left')\n",
    "df_main = df_lod_data.merge(df_reg, on='Name', how='left')\n",
    "\n",
    "\n",
    "df_main[['Lebensdaten', 'Konfession']] = df_main.apply(adjust_metadata, axis=1)\n",
    "# Entfernt die ursprünglichen Lebensdaten-Spalten, da sie nun redundant sind\n",
    "df_main.drop(columns=['Lebensdaten_LOD', 'Lebensdaten_Register'], inplace=True)\n",
    "\n",
    "# Ausgabe des Ergebnisses\n",
    "print(df_main)\n",
    "\n",
    "# --- Schritt 6: Personen-DataFrames zusammenführen ---\n",
    "# Hier werden die Personennennungen aus dem Bericht (df_mapping) mit den Metadaten aus dem Register (df_reg) zusammengeführt.\n",
    "# Das Ergebnis ist ein umfassender DataFrame, der relevante Informationen zu den im Bericht genannten Personen enthält.\n",
    "\n",
    "# Stellt sicher, dass die 'Name'-Spalten vor dem Mergen bereinigt sind\n",
    "df_mapping['Name'] = df_mapping['Name'].str.strip()\n",
    "df_reg['Name'] = df_reg['Name'].str.strip()\n",
    "\n",
    "# Führt die beiden DataFrames basierend auf dem Personennamen zusammen (Left Join)\n",
    "merged_df = pd.merge(df_mapping, df_reg, on='Name', how='left').fillna('').astype(str)\n",
    "\n",
    "# Definiert die gewünschte Spaltenreihenfolge neu\n",
    "# Extrahiert alle Spalten ausser 'Nennung'\n",
    "cols = [col for col in merged_df.columns if col != 'Nennung']\n",
    "# Fügt die breite Spalte 'Nennung' rechts hinzu\n",
    "cols.append('Nennung')\n",
    "# Erstellt einen DataFrame mit der neuen Spaltenreihenfolge\n",
    "merged_df = merged_df[cols]\n",
    "\n",
    "# Gibt den DataFrame in der Konsole aus\n",
    "print(\"DataFrame mit Personendaten:\")\n",
    "print(merged_df)\n",
    "# Gibt die Anzahl der Personen im zusammengeführten DataFrame aus\n",
    "print(f\"Zusammengeführter DataFrame enthält {len(merged_df)} Einträge.\")\n",
    "\n",
    "# --- Schritt 6: Ergebnisse speichern & Excel formatieren ---\n",
    "# Dieser letzte Schritt speichert den zusammengeführten DataFrame\n",
    "# sowohl als CSV- als auch als Excel-Datei.\n",
    "# Die Excel-Datei wird zusätzlich formatiert: Spaltenbreiten werden angepasst\n",
    "# und die Kopfzeile wird hervorgehoben, um die Lesbarkeit zu verbessern.\n",
    "\n",
    "# Bereinigt den Dateinamen für die Ausgabe (ersetzt Umlaute, Leerzeichen etc.)\n",
    "new_filename = report_name.lower().replace('ä', 'ae').replace('ö', 'oe').replace('ü', 'ue').replace('ß', 'ss').replace(' ', '_')\n",
    "\n",
    "# Definiert die Ausgabedateien für CSV und Excel\n",
    "output_csv = new_filename.replace('.xml', '_personen_metadaten.csv')\n",
    "output_xlsx = new_filename.replace('.xml', '_personen_metadaten.xlsx')\n",
    "\n",
    "# Speichert den DataFrame als CSV-Datei (UTF-8 mit BOM für bessere Kompatibilität)\n",
    "merged_df.to_csv(output_csv, sep=';', index=False, encoding='utf-8-sig')\n",
    "# Speichert den DataFrame als Excel-Datei\n",
    "merged_df.to_excel(output_xlsx, index=False)\n",
    "\n",
    "# Excel-Datei: Anpassung der Spaltenbreite und Styling für bessere Lesbarkeit\n",
    "wb = load_workbook(output_xlsx)\n",
    "ws = wb.active # Aktiviert das erste Arbeitsblatt\n",
    "\n",
    "# Styling-Definitionen für Kopfzeile\n",
    "header_font = Font(bold=True) # Fettgedruckte Schrift\n",
    "header_fill = PatternFill(\"solid\", fgColor=\"DDDDDD\") # Hellgrauer Hintergrund\n",
    "\n",
    "# Geht jede Spalte durch, um die Breite anzupassen und Kopfzeile zu formatieren\n",
    "for col_num, column_cells in enumerate(ws.columns, 1):\n",
    "    max_length = 0\n",
    "    for cell in column_cells:\n",
    "        # Formatiert die Kopfzeile (erste Zeile)\n",
    "        if cell.row == 1:\n",
    "            cell.font = header_font\n",
    "            cell.fill = header_fill\n",
    "        try:\n",
    "            # Ermittelt die maximale Länge des Zellinhalts in der Spalte\n",
    "            if cell.value:\n",
    "                max_length = max(max_length, len(str(cell.value)))\n",
    "        except:\n",
    "            # Ignoriert Fehler beim Zugriff auf Zellwerte\n",
    "            pass\n",
    "    # Setzt die Spaltenbreite basierend auf der maximalen Länge, plus etwas Puffer\n",
    "    ws.column_dimensions[get_column_letter(col_num)].width = max_length + 1\n",
    "\n",
    "wb.save(output_xlsx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
